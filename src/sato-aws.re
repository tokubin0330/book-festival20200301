= モダンなWEBアプリケーション思考でつくるAWSアーキテクチャ

== はじめに

今ではクラウド利用がとても一般的になり、オンプレミスからクラウドに移行する企業の事例もたくさん目にするようになりました。
そこでは、こんなメリットが多く語られるのではないでしょうか。

 * 初期コストを抑えられ、サービスの成長とともにスケールできる
 * サービス開発、リリースの迅速化
 * 運用コストを抑えられる
 * 高いセキュリティと可用性が得られる

どれも、クラウド化で得られるメリットであることは間違いありません。まさにバラ色の世界が待っていそうです。
しかし、ただオンプレミスからクラウドに載せ替えただけでは、そのメリットをほとんど受けることはできないでしょうし、
逆にコスト高になってしまうことさえあります。@<b>{バラ色の世界の住人になるには準備が必要なのです。}
クラウドにはクラウドの思想があり、
それ沿ったアプリケーション設計、インフラストラクチャ構築を行ったものだけが
クラウド化のメリットを最大限享受できるものなのです。@<br>{}

AWSが公開しているホワイトペーパーには、このような一節があります。

//quote{
十分なリソースや時間が与えられれば、大半のプラットフォーム上で耐障害性の高いソフトウェアシステムの構築が可能です。
AWSプラットフォームでは、最低限の人的作業と、最低限の事前投資により、耐障害性の高いシステムの構築が可能である点がユニークなのです。
//}

耐障害性について語られているものですが、
AWSだから耐障害性が高いのではなく、同レベルの耐障害性を迅速に低コストで実現できるのがAWSです。
そのためには、AWSに対しての正しい知識が必要です。
この章では、AWS上にアプリケーションを展開するための考え方や、
AWSのマネージドサービスの使い所をご紹介していきたいと思います。

== クラウドネイティブとは

最近、クラウドネイティブという言葉をよく耳にするようになりました。
クラウド上で展開されることを前提としたアプリケーションを指す言葉ですが、具体的にどんなものなのでしょうか。
Cloud Native Computing Foundation（CNCF）@<fn>{cncf}が公開しているクラウドネイティブの定義@<fn>{site}
を参考にしてみましょう。

//quote{
クラウドネイティブ技術は、パブリッククラウド、プライベートクラウド、ハイブリッドクラウドなどの近代的でダイナミックな環境において、スケーラブルなアプリケーションを構築および実行するための能力を組織にもたらします。 このアプローチの代表例に、コンテナ、サービスメッシュ、マイクロサービス、イミューダブルインフラストラクチャ、および宣言型APIがあります。
これらの手法により、回復性、管理力、および可観測性のある疎結合システムが実現します。 これらを堅牢な自動化と組み合わせることで、エンジニアはインパクトのある変更を最小限の労力で頻繁かつ予測どおりに行うことができます。
//}

つまり、クラウドネイティブなアプリケーションとは、クラウドで確立された技術・手法を利用して、疎結合なコンポーネントによりサービスが提供され、回復力があり監視され管理しやすく、素早く開発できて、最小限の心理的負担でデプロイが行えるように構成されたアプリケーションと言えるのではないでしょうか。

#@warn(あとで書く)
//footnote[cncf][AWSやGoogle、IBMやMicrosoft、RedHat等、様々な企業が参加しているクラウドネイティブアプリケーション開発・運用環境に関する技術の標準化を推進している団体です。]
//footnote[site][https://github.com/cncf/toc/blob/master/DEFINITION.md]

//embed[latex]{
\clearpage
//}

== The Twelve Factor App - 12のルール

クラウドネイティブにマッチしたアプリケーション設計でなければ、そのシステムはクラウドがもたらす恩恵を受けることができません。
そこで、ここではアプリケーションの設計にフォーカスしてみましょう。@<br>{}

クラウドネイティブにマッチしたアプリケーションにするためには、どのような思想で設計すればいいのでしょうか。
その思想を理解するための助けになるのが、herokuの開発者が2011年に提唱したTwelve Factor App@<fn>{tfa}です。
クラウド上で展開するモダンWEBアプリケーション開発するための方法論が書かれており、発表からすでに8年が経過している今でもかわらないベストプラクティスです。
これを読み解いていきましょう。

//footnote[tfa][https://12factor.net/]

=== コードベース

==== バージョン管理されている1つのコードベースと複数のデプロイ@<br>{}

コードはバージョン管理すること、アプリケーションとコードベースが1対1であることが重要です。
デプロイ時に、エンジニアにかかる心理的負担軽減のためにデプロイの容易性と迅速性を得るための
コード管理方法であると解釈できます。
迅速にデプロイできるということは、
デプロイが原因でトラブルが発生したときも以前のバージョンにすぐにロールバックできるメリットもありますし、
心理的な負担が減少することで積極的なリリースも可能になります。
これは継続的デプロイに必要な要素でもあります。

=== 依存関係

==== 依存関係を明示的に宣言し分離する@<br>{}

依存関係管理ツール@<fn>{composer}を利用して、アプリケションコードとは分離することが重要です。
ツールを使って依存関係を管理していることで、セットアップの単純化と自動化ができるため、
新たに加わった開発者がすぐに開発できるというメリットをもたらします。
これは継続的インテグレーションに必要な要素です。

//footnote[composer][PHPのComposer、nodejsのnpm等]

=== 設定

==== 設定を環境変数に格納する@<br>{}

実行環境で変化する設定値は環境変数@<fn>{env}に格納して、
設定をコードから切り離すことで、開発から本番まで同一のコードで動かすことができます。
これによって、デプロイの手順を統一化を図ることができるようになり、その先には自動デプロイがあります。

//footnote[env][環境変数を使用するのは言語/OSを問わず利用可能なため]

=== バックエンドサービス

==== バックエンドサービスをアタッチされたリソースとして扱う@<br>{}

アプリケーションとバックエンドサービスというライフサイクルが違うものは疎結合な状態にしておくことで、
デプロイ状況に影響を受けずに、障害発生時も局所的な対応で復旧が可能になります。

=== ビルド、リリース、実行

==== ビルド、リリース、実行の3つのステージを厳密に分離する@<br>{}

ここは、この３つのステージが一方通行で実行されていくこと、リリースは常に一意のIDを持つこと、
人の判断や確認が介在するステージと、自動化されるステージを明確にしておくことが重要です。
一方通行であることで、実行ステージのコードは必ずコードベースのコードと一致することが保証され
デグレード等のトラブルが入り込みにくくなりますし、
自動化されたステージが明確であることで、インスタンス数が変化する際にも
人が介在することなく新しいインスタンスに自動でデプロイすることができるようになります。


また、デプロイツールを使用することで以前のバージョンに
かんたんにロールバックする仕組みも導入できるためここでは利用が推奨されています。

=== プロセス

==== アプリケーションを1つもしくは複数のステートレスなプロセスとして実行する@<br>{}

プロセスはステートレスかつシェアードナッシングであるということが重要です。
これは、クラウドネイティブなインフラストラクチャでは状況に応じて
常にインスタンス数が変化するため、
どのリクエストがどのインスタンスで処理されるのかわかりません、
そのため、永続化が必要なデータはバックエンドサービス等に格納して
必要であればリクエストの度に呼び出す必要があります。@<br>{}

また、ELBの機能の1つであるスティッキーセッションも禁止されています。
この機能は、ユーザーのセッション情報に応じて接続するインスタンスを固定化してセッションを維持するというものですが、
クラウドネイティブなインフラストラクチャは常にインスタンス数が変化しており、インスタンスが突然終了することもあります。
そうなればセッションは切れてユーザー体験が著しく落ちますし、
また、接続先が固定されていると、一部のインスタンスに負荷の偏りが発生してしまうことや、
スケールアウトしても新しいインスタンスにトラフィックが分散されず、
インスタンスの利用効率は落ちてユーザー体験も改善されず、良いことは何もありません。@<br>{}

スティッキーセッションは、レガシーなアプリケーションを補助するための機能ですので利用してはいけません。

=== ポートバインディング

==== ポートバインディングを通してサービスを公開する@<br>{}

いわゆる、マイクロサービスのような形を想像すると理解しやすくなります。
プロセス（サービス）が他のプロセス（サービス）と接続する場合は、
ポート番号を公開してTCPまたはUDPで接続できるようにしましょう。
これによって、あるアプリケーションが他のアプリケーションのバックエンドサービスになることもできます。

=== 並行性

==== プロセスモデルによってスケールアウトする@<br>{}

スケールアップには限界があります。
そのため、ステートレス、シェアードナッシングなTwelve Factor Appプロセスの性質を生かして、
ワークロードの種類でプロセスを分割し、
プロセス単位でスケールアウトすることでより大きなワークロードに対応できるようになります。

=== 廃棄容易性

==== 高速な起動とグレースフルシャットダウンで堅牢性を最大化する@<br>{}

高速な起動ができれば、ワークロードの変化に対する追従性が高まりスムーズにスケールができるようになりますし、
また、デプロイやロールバックが素早く完了するということはリリースでの心理的負担が減ることになり、
積極的なリリース施策を取ることも可能になります。
高速な起動を実現するためには、
コンテナであればイメージサイズを可能な限り小さく保たなければいけませんし、
インスタンスであれば起動ステップを少なくすること等を意識しなければいけません。

=== 開発/本番一致

==== 開発、ステージング、本番環境をできるだけ一致させた状態を保つ@<br>{}

本番と同じバックエンドサービスを開発マシンで動かしながらの開発も、
現在のマシンスペックであればそれほど苦労なくできるようになってきていると思いますので、
環境は可能な限り一致させましょう。
これについては、Docker等のコンテナ技術を使うことも検討しましょう。

=== ログ

==== ログをイベントストリームとして扱う@<br>{}

インスタンスはいつ落ちるかわかりませんし、
常に台数が変化するものなのでインスタンスのローカルにログを保存することはできません。
ですので、ログは標準出力ストリームとして出力し、ログ集約サービスを利用してログを集約させましょう。
AWSであればCloudWatch Logsがすぐに使えるマネージドサービスです。

=== 管理プロセス

==== 管理タスクを1回限りのプロセスとして実行する@<br>{}

1度限りしか実行しない管理用のコードも、アプリケーションコードと一緒にデプロイしましょう。
ただし、デプロイ時に自動実行する場合は1度限りの実行が保証される方法を取ることと、
ロールバック時のことを考慮することを忘れないようにしてください。

== AWSのネットワークを構成するコンポーネント

ここまでは、クラウド上に展開するアプリケーションの設計思想を解説してきました。
ここからは、クラウドネイティブアプリケーションのインフラストラクチャ設計に必要な、
AWSインフラストラクチャコンポーネントの基礎的な知識を解説していきたいと思います。

=== リージョン

世界をいくつかのエリアに分けた地域別のAWSサービスの集合体。
各リージョンは完全に独立していますが、すべてが同じ設計となっていますが、
リージョンによって利用可能なサービスが異なることがあります。
物理的に利用者に近いリージョンを選ぶことで、ネットワークの遅延を軽減することが可能です。

=== VPC

AWSのリージョン上に、任意のIPアドレスレンジを指定して、
プライベートネットワーク空間を構築するためのコンポーネントです。
VPCは論理的に隔離されていますので、同じアドレスレンジを持つVPCを複数作成することが可能です@<fn>{vpcrange}。
これによって論理的なネットワークの分離、各種コンポーネントを接続してネットワーク境界のコントロールを行います。
AWS上に仮想的なデータセンターを構築するようなイメージです。

//footnote[vpcrange][アドレスレンジがかぶるVPC同士をVPCを接続するサービス（VPCピアリング等）で接続することはできませんので利用予定がある場合には注意が必要です。]

=== アベイラビリティゾーン

どのリージョンにも2つ以上のアベイラビリティゾーン（以下AZ）が存在@<fn>{azlocal}しており、地理的・電源的・ネットワーク的に分離されています。
1つのAZは1つ以上のデータセンターで構成されていて、6つのデータセンターで構成されるAZも存在しています。
また、1つのデータセンターが2つのAZに所属することはありません。
データセンター間は通常1ms未満のレイテンシが確保されており、AZ間も数msのレイテンシが確保されています。
複数のAZを利用して冗長構成をとることで、サービス単体のSLAを超えることが可能です。

====[column] アベイラビリティゾーンのマッピングについて

アカウントごとにゾーンのマッピングは異なり、Aアカウントの1aゾーンがBアカウントでも1aであるとは限りません。
同じAZを知りたい場合にはAZ IDを確認しましょう。

====[/column]

//footnote[azlocal][大阪ローカルリージョンを除く]

=== サブネット

VPCのアドレス空間を分割するためにサブネットを作成します。インスタンスはサブネット内に配置されます。
サブネットは1つのAZに所属することができます。
インターネットに接続しないプライベートサブネットも作成可能です。
構成や用途、セキュリティを考慮してパブリックサブネット、プライベートサブネットを使いわけましょう。
（NATゲートウェイをパブリックサブネットに置き、WEBサーバーとアプリケーションサーバー、DBサーバーはプライベートサブネットに置く等）

=== ルートテーブル

仮想ルータが、サブネットにアタッチされたルートテーブルをlookupしてパケットのルーティングを行います。@<fn>{subnetroute}
ルートテーブルにないルートにはルーティングされません。ルートテーブルはサブネット単位で作成できます。

//footnote[subnetroute][VPC内のサブネット間のルーティング情報は削除することができません。サブネット間の通信を拒否したい場合はNACLかセキュリティグループで設定を行いましょう。]


=== ネットワークACL、セキュリティグループ

VPCのネットワークトラフィックを制御するファイアウォールとして、ネットワークACL（NACL）とセキュリティグループがあります。
それぞれ影響範囲やルールの適用されかたに違いがありますので、よく理解しておきましょう。

#@# ==== ネットワークACL

#@# サブネットにアタッチできるステートレスファイアウォールで、NACLと省略されたりします。

#@#  * サブネット単位で影響
#@#  * 許可/拒否をIN/OUTで指定可能
#@#  * ステートレスなため戻りのトラフィックも明示的に許可設定が必要
#@#  * 設定の順番通りにルールが適用され、ルールに適合したらそれ以上適用されない

#@# ==== セキュリティグループ

#@# インスタンスにアタッチできるステートフルファイアウォールです。

#@#  * インスタンス単位で影響
#@#  * 許可のみをIN/OUTで指定可能
#@#  * ステートフルなため戻りのトラフィックは考慮しなくてOK
#@#  * すべてのルールが適用される

//table[nacl_vs_sg][ネットワークACL vs セキュリティグループ]{
ネットワークACL	セキィリティグループ
---------------------------------
サブネット単位で影響	インスタンス単位で影響
許可/拒否をIN/OUTで指定可能	許可のみをIN/OUTで指定可能
ステートレスなため戻りの@<br>{}トラフィックも明示的に許可設定が必要	ステートフルなため@<br>{}戻りのトラフィックは考慮しなくてOK
設定の順番通りにルールが適用され@<br>{}ルールに適合したらそれ以上適用されない	すべてのルールが適用される
//}

#@# == AWSのサービス別特長

#@# AWSのサービスを活用することが、AWS上で良いアプリケーションを構築するための必要要素です。
#@# AWSのサービスにはグローバル、リージョン、アベイラビリティゾーン固有のサービスがあり、境界が存在しています。
#@# 境界を超えてアクセスする場合には、制限や遅延が発生するものもありますので、それを理解した上で、上手にアプリケーションに組み込んでいく必要があります。

#@# === EC2

#@# 仮想サーバーで、EC2はElastic Compute Cloudの頭文字を取ったものです。
#@# 秒単位の従量課金制で起動時間とインスタンスのスペックに応じて料金が発生@<fn>{ec2price}します。
#@# OSはLinux系とWindows系から選択できますが、選択したOSによってはライセンス料金が発生する場合がありますので注意が必要です。
#@# インスタンスの世代が上がるほど（t2→t3等）、低コスト高性能になりますので定期に見直すことでコスト削減にも繋がります。

#@# サーバーのローカルストレージとしてEBS（Elastic Block Store）と組み合わぜて利用されることが多いです。
#@# オンプレミスのサーバーと変わらない操作感が得られるため、移行先として真っ先に選択肢として上がるサービスではないでしょうか。

#@# //footnote[ec2price][実際の利用料はインスタンスの料金、トラフィック料金、EBSを利用していたら場合はその料金が発生します]

#@# === ELB

#@# === RDS

#@# === DynamoDB

#@# === CloudFront

#@# === Route53

#@# === ElastiCache

#@# === ECS

#@# ==== Fargate

#@# ==== ECR

#@# === Code3兄弟

#@# ==== CodeCommit

#@# ==== CodeBuild

#@# ==== CodeDeploy

#@# === CloudWatch

#@# ==== CloudWatch Events

#@# ==== CloudWatch Logs

== 3層WEBアプリケーションのケース別構成例

それでは、よくある3層WEBアプリケーションを例に、AWSサービスがどのようなケースで有効なのか、また、そのサービスの詳細を見ていきましょう。

=== 基本形

まずは、3層WEBアプリケーションの基本構成例です。（@<img>{3tier_standard}）
基本的な形ですが、いかにこの形に寄せていくかが大事です。

//image[3tier_standard][AWSの標準的な3層WEBアプリケーションの構成例][scale=0.8]{
//}

それでは、利用されているコンポーネントについて解説します。

==== IGW

正式名称はInternet Gateway。
インターネットからのトラフィックはInternet Gatwayを通り、ALBに到達します。
このInternet Gatewayは、VPCとインターネットとの間の通信を可能にするVPCコンポーネントで、冗長性と高い可用性を備えており状況に応じて水平スケーリングされるため
ネットワークトラフィックの可用性や帯域幅の制約はありません。

==== ALB

AWSマネージドなロードバランサーで、正式名称はElastic Load Balancing、省略してELBです。
ELBには世代と機能により下記の3種類あり、要件に合わせて選択します。

 * Application Load Balancer（ALB）
 * Network Load Balancer（NLB）
 * Classic Load Balancer（CLB）

レイヤー7の負荷分散可能なロードバランサーであるApplication Load Balancerは、
複数のAZに対してトラフィックを分散させることができ、
トラフィック量に応じてロードバランサー自身が自動的にスケーリングし可用性を確保しています。
他にも代表的な特徴として下記のような特徴があります。

 * オートスケーリングと組み合わせることで、動的に変化するインスタンスに対してトラフィックをルーティングします。
 * ヘルスチェック機能で正常なインスタンスにのみトラフィックをルーティングします。
 * HTTPSターミネーション機能で、クライアントとロードバランサー間でのHTTPS通信をサポートしています。
 * インターナルロードバランサーとして、サブネット内のトラフィックを分散させることもできます。

 この構成では、ALBをインターネットフェイシングとして配置し、IGWからトラフィックを受け、配下のEC2（ターゲットグループ）に分散しています。

==== EC2

仮想サーバーで、Elastic Compute Cloudの頭文字を取ってEC2と省略されます。
オンプレミスのサーバーと変わらない操作感が得られるため、移行先として真っ先に選択肢として上がるサービスです。
秒単位の従量課金制で起動時間とインスタンスのスペックに応じて料金が発生@<fn>{ec2price}します。
OSはLinux系とWindows系から選択できますが、選択したOSによってはライセンス料金が発生する場合がありますので注意が必要です。
インスタンスの世代が上がるほど（t2→t3等）、低コストで高性能になりますので定期に見直すことでコスト削減にも繋がります。
サーバーのローカルストレージとしてEBS（Elastic Block Store）と組み合わぜて利用されることが多いです。@<br>{}

このEC2とオートスケーリングを組み合わせて、
トラフィックに応じたコンピューティングリソースの需要に水平スケールで対応します。

=====[column] 垂直スケール戦略が取られない理由

WEBアプリケーションに要求されるコンピューティング力は絶えず変化しますし、どこまで要求されるか予測ができません。

垂直スケールでもインスタンスのコンピューティング力を上げることは可能ですが、
スペックには上限がありますし、スペック変更時にダウンタイムが発生します。
また、冗長性がないため可用性も確保されません。

絶えず変化する状況へ迅速に、そしてコスト効率よく無制限に対応するためにはインスタンス数を増減させる水平スケール戦略が非常に有効なのです。

=====[/column]

//footnote[ec2price][実際の利用料はインスタンスの料金、トラフィック料金、EBSを利用していた場合はその料金が発生します]

==== RDS

AWSマネージドなリレーショナルデータベースサービスで、正式名称はAmazon Relational Database Serviceです。
データベースエンジンには、
MySQL、MariaDB、PostgreSQL、Microsoft SQL Server、Oracle、Amazon Auroraの6種類のエンジンから選択できます。
セキュアで高い可用性と耐久性をもち、マスタースレーブ構成（マルチアベイラビリティ構成）や
リードレプリカ構成などを簡単にプロビジョニングできるように設計されています。
トランザクションログを含む自動バックアップでは、
バックアップ保持期間の任意の時点（最大5分前まで）にさかのぼってデータベースを復元でき、
また、無停止でのスケールアップや自動パッチ適用等、運用にかかる負担も低く抑えられています。@<br>{}

この構成では、永続化が必要なデータはすべてRDSに保存します。

==== ElastiCache

AWSマネージドなRedis、Memcached互換のインメモリデータストアサービスです。
一部でElasti"c"Cacheとの表記を見かけますが、正しくはCが重複しないElastiCacheです。
マルチアベイラビリティ構成での自動フェイルオーバー、リードレプリカ構成、スケーリング等
スケーラブルかつ高可用性かつ高い耐久性を持ち、ソフトウェアパッチの適用、クラスタの維持管理等はすべてAWSが行ってくれます。@<br>{}

この構成では、セッションデータのストア先に利用します。こうすることで、クライアントがどのインスタンスに接続されてもセッションを維持することが可能です。



=== 一部トラフィックをS3へオフロードする

前節の構成でもトラフィックの変化量が緩やかな場合はうまくいきますが、
トラフィックが大きくスパイク（5分間で50%以上等）するような状況では
下記のような状態になり、すべてのトラフィックをさばくことが難しくなります。

 * ロードバランサーのスケールが間に合わないことがある
 * EC2のオートスケーリングも間に合わない場合がある

スパイクすることが予めわかっている場合は、
サポートへロードバランサーの暖気申請をする方法もありますが、
サポートプランがビジネス以上でないと申請することができないですし、突然のスパイクには対応できません。
そこで、WEBサーバーの静的なコンテンツをS3から配信することで、ロードバランサーへのトラフィックをオフロードする構成を考えます。（@<img>{3tier_s3_offload}）

//image[3tier_s3_offload][S3へのオフロード構成例][scale=0.8]{
//}

前節ではインターネットからのトラフィックをALBで直接受けていましたが、それをCloud Frontで受けて
リクエストのパスに応じてALBまたはS3にCloud Frontからリクエストを送ることで、
画像やHTMLファイル、Javascriptファイルなど静的なファイルはS3から、
動的なファイルはWEBアプリケーションから配信し、ALBやWEBサーバーにかかる負荷を下げます。

==== Cloud Front

AWSマネージドなCDNサービスです。
Cloud Front経由でオリジンへアクセスすると、Cloud Frontがオリジンからのレスポンスをキャッシュし、
キャッシュにヒットした場合には、Cloud Frontがキャッシュを返すことでオリジンの負荷を下げる効果があります。
また、キャッシュを利用しない設定も可能で、その場合でも以下のようなパフォーマンス向上効果があります。

 * AWSバックボーンネットワークの活用
 * レイテンシベースルーティング
 * ネットワークパスのTCP/IP最適化
 * キープアライブ接続によりRTTを削減
 * SSL/TLS最適化

==== S3

正式名称はAmazon Simple Storage Serviceで、
高い耐久性と拡張性を備えたオブジェクトストレージです。
容量無制限ですが、1オブジェクト最大5TBまでという制限があります。
様々なAWSのサービスと連携できるため、データレイクとしての利用にも最適です。

====[column] S3のデータ整合性モデル

S3はAmazonのデータセンターに配置された複数のサーバー間でデータを複製することで高い可用性を保っており、
アップロードされたオブジェクトは順次分散コピーされていきます。
そのため、全体に更新が行き渡るまでは更新前の結果が返ってくることがありますが、
いずれ全体に更新が行き渡れば更新後の結果が返ります。これがS3の結果整合性モデルです。
また、単一のオブジェクトに対する更新はアトミックであるため、更新途中の不完全なデータや壊れたデータが返ることはありません。
この点を考慮して積極的に活用していきましょう。

====[/column]

=== RDSのボトルネックに対応する

今回は、さらにRDSがボトルネックとなった場合の対応を考えていきましょう。
RDSの書き込み負荷に対しては、Masterのインスタンスをスケールアップすることで対応します。
読み取り負荷についてはリードレプリカが有効ですので、リードレプリカを作成してデータベースへのアクセスを分散させましょう。
また、RDSには重すぎるRead/WriteやKVSに向くデータは積極的にDynamoDBやElastiCacheを活用してRDSにかかる負荷を小さくしていくことが主な対応方法になります。

==== RDS ReadReplica

RDSのリードレプリカは読み込み専用で、Masterから非同期でレプリケーションされます。
複数台作成することができますし、リージョンを超えて作成することもできます。
非同期のため、Masterの更新結果が反映されるまでラグが発生します。@<br>{}

この構成では、図の構成の都合上１つのAZに配置していますが
複数のAZに配置して可用性を高めることはとても重要です。

==== DynamoDB

高い可用性と耐久性をもち、無制限にスケール可能なKey-Valueのドキュメントデータベースです。
テーブルの容量に制限はありませんが、項目数や項目のサイズに制限があります。@<br>{}

この構成では、RDSの書き込み負荷も上がっているため、
KVSに向くデータをDynamoDBに保存するような利用を想定をしています。

==== Route53

Route53はSLA100%のDNSサービスです。
パブリックなDNS以外にも、VPC内のプライベートなDNSの解決にも使えます。@<br>{}

この構成では、複数台で構成されたRDS ReadReplicaのDNSラウンドロビンに利用します。

//image[3tier_rds_replica][RDSボトルネックの対応例][scale=1.0]{
//}

#@# === マルチリージョン構成によるディザスタリカバリ

#@# 最後は、マルチリージョン構成によるディザスタリカバリの一例をご紹介したいと思います。
#@# これはウォームスタンバイと言われるタイプのもので、リージョンに障害が発生した場合には、
#@# 別リージョンにレプリケーションしておいた環境にトラフィックを流すことで復旧させるものです。@<br>{}

#@# ポイントとしては、S3のクロスリージョンレプリケーション、
#@# DynamoDBのグローバルテーブル、RDSのリードレプリカを利用しデータを別リージョンに常にコピーしておきます。
#@# CloudFrontのオリジンフェイルオーバーを設定しておき、プライマリオリジンで障害が発生した際にはトラフィックがセカンダリオリジンに流れるようにします。

#@# //image[3tier_cr_dr][マルチリージョン構成によるディザスタリカバリ][scale=1.0]{
#@# //}

//embed[latex]{
\clearpage
//}

== まとめ

ここまで、モダンなWEBアプリケーションの思想とアーキテクチャを見てきましたが、
ここで紹介したものはAWSのサービスのほんの一部の機能でしかありません。
AWSではその他にも多くの機能や専門的なサービスが提供されていて、
それまでは一部の大企業でしか利用できなかったような膨大なコンピューティングリソースや、
専門的な知識が要求されるシステムを個人でも手軽に安く利用することが可能です。
上手に使えば個人が大企業に匹敵するようなアプリケーションを展開することも不可能ではありませんので、
興味があればAWSのもっとディープな世界に飛び込んでみてはいかがでしょうか。
