= Amazon SageMaker入門

== Amazon SageMakerとは
Amazon SageMakerはAWSが提供している機械学習のマネージドサービスです。機械学習モデルを構築する上で生じる面倒なタスクをAmazon SageMakerが対応してくれます。例えば学習用インフラ環境の構築や推論用モデルのAPI構築などです。

私は今までいくつかの画像認識モデルを作成してきましたが、学習したモデルの推論に使うためのAPI構築はセキュリティやパフォーマンスといった面でとても構築が大変でした。
そういったところをAmazon SageMakerがサポートしてくれるのは開発者にとってメリットがあると思います。

== この章の対象読者
本章についてですが、機械学習やディープラーニングについての説明は行いません。ですのである程度概要について理解している方を対象の読者としています。

 * ディープラーニングを書籍や動画などで勉強している
 * 畳み込みニューラルネットワークなどの概要を知っている
 * Jupyter Notebookを使ったことがある
 * Google Colabを使ったことがある
 * 画像認識などのサービス開発をやってみたい
 * Amazon SageMakerを使ったことがない

このよう読者にむけてAmazon SageMakerを導入するメリットや実装方法について紹介していきます。

また、すでにAmazon SageMakerを導入している場合や機械学習についてまったく知らないという読者には得られる内容が少ないと思います。

== Amazon SageMakerの特徴
機械学習のプロジェクトにAmazon SageMakerを導入するメリットを紹介します。

=== 開発環境の用意が簡単に行える
機械学習用の環境構築を自前で行うにはライブラリ・フレームワークのインストールやGPU環境の構築などに時間がかかってしまいます。
またハイパーパラメータの検証を行うなどを目的とした複数の学習ジョブを並列に実行する環境の用意や１つの学習ジョブを分散学習する環境の構築も面倒です。
Amazon SageMakerではそういった環境の構築が簡単に行えるためすぐに開発に入ることができます。

=== 必要な時だけGPU環境が作成される
ディープラーニングでは学習時にGPU環境を用いると高速に学習を行えますが、それ以外でGPU環境をスタンバイしておく必要はありません。
Amazon SageMakerでは学習が始まるタイミングにGPU環境が用意され終了すると自動的にインスタンスが削除されるので、学習している時間だけ費用が発生します。
Amazon EC2だと学習時だけGPU環境が立ち上がり、終わるとシャットダウンするという構成にするのが難しいのでそういった点もAmazon SageMakerのメリットです。

=== 推論用APIの自動構築
学習させたモデルはたった1行でデプロイすることが可能です。Amazon SageMakerがAPIエンドポイントを提供してくれるので、Amazon EC2などに推論用の環境を構築する必要はありません。
またマネージドサービスなのでAPIサーバーのメンテナンスも必要ありません。
//ABテストもできるらしいので検証

=== 開発・学習・推論の好きなところだけにAmazon SageMakerを利用できる
Amazon SageMakerでは、機械学習モデルを容易に開発・学習・推論用にデプロイがするためのフルマネージドサービスですが、特定のフェーズだけを利用することも可能です。

 * 開発用にJupyter Notebookを利用する
 * 外部で開発したコードをAmazon SageMakerに持ち込んで学習する
 * 学習したモデルをAmazon SageMaker以外の環境へデプロイする

など条件の合うフェーズのみAmazon SageMakerを導入することができます。

=== AWSのサービスと連携が簡単
最近のWebやアプリサービスのインフラにAWSを採用している企業は、Amazon S3にコンテンツが保管してあるのでデータを簡単にAmazon SageMakerと連動することが可能です。

=== 学習モデルの再現性
全ての学習ジョブについては、Amazon SageMakerのトレーニングジョブに履歴が残っているため、学習したモデルをいつでも再現することができます。

=== その他
他にもAmazon SageMakerを利用するとこんなメリットが・・・？

 * トレーサビリティ

== Amazon SageMakerを始める
ここからは機械学習モデルの構築を進めながらAmazon SageMakerの説明に進んでいきたいと思います。
Amazon SageMakerの画面説明だけをしてもわかりづらいと思うので「じゃんけんを画像分類するモデル」を構築して進めていきましょう。

#@# ここに絵を挟んでみてもいいかも

=== 画像認識モデル開発から推論までの流れ
じゃんけんの画像分類モデルを開発するまでの流れを以下にまとめます。

 1. 学習用の画像を準備してAmazon S3に保管
 2. Jupyter Notebookを使用して画像分類モデルを作成
 3. 学習を実行して精度を可視化
 4. モデルをデプロイしてAPIとして呼び出せるようにする

学習データの準備については説明を省きます。今回のような手の画像については、自分で作成をしてもいいし世界中にデータセットが存在するのでそれらを利用するのも良いでしょう。
書籍に合わせて開発を行う方は、自身で作成したS3のBucketに @<b>{rock} / @<b>{paper} / @<b>{scissors} というフォルダを用意しておいてください。

公開されているデータセットだと以下のようなものがあります。

Rock-Paper-Scissors Images
@<br>{}
@<href>{https://www.kaggle.com/drgfreeman/rockpaperscissors}

Rock Paper Scissors Dataset
@<br>{}
@<href>{https://www.kaggle.com/sanikamal/rock-paper-scissors-dataset}

Sign-Language-Digits-Dataset
@<br>{}
@<href>{https://github.com/ardamavi/Sign-Language-Digits-Dataset}
こちらは0~9までのハンドサインの画像セットになりますが、0がrock/2がscissors/5がpaperに利用できるためデータを限定して利用します。

それぞれのデータセット見てみると背景が白か緑しかないので、過学習になってしまうのでは？と思う方もいるかも知れませんが先に進めていきましょう。

=== 画面の説明
Amazon SageMakerの画面について紹介していきます。
今回取り上げるのは左カラムにある「ノートブック」「トレーニング」「推論」になります。

=== 開発
まずは機械学習モデルの開発を行います。開発と学習はほぼセットになっているので、精度がでれば推論に出せますがそれまでは開発と学習をぐるぐると回している状態になります。


==== インスタンスの準備
開発を始めるにはJupyter Notebookインスタンスの作成から始まります。

//image[create-instance][学習用インスタンス作成][scale=0.8]

=== 学習

=== 推論

----------ここまでが第１弾----------
== Raspberry Piに組み込むには
Amazon SageMaker Neoを利用してIoTデバイスに最適化された推論モデルにする。
 
 * AWS IoT Greengrassを使用する
 * 学習モデルを手動で組み込む

== Amazon SageMaker Neoとは

=== AWS IoT Greengrassを使ってデプロイする

----------ここまでが第２弾----------

== Amazon SageMaker の活用事例
そんなない。

== Amazon SageMaker のその他サービス
Amazon SageMaker Ground Truthとか紹介

----------⬆︎書かなくていいけど必要があれば書く----------

== まとめ

== サンプルコードのダウンロード先について